diff --git a/example/multi_threaded_echo_c++/CMakeLists.txt b/example/multi_threaded_echo_c++/CMakeLists.txt
index d0633351..97d15cd1 100644
--- a/example/multi_threaded_echo_c++/CMakeLists.txt
+++ b/example/multi_threaded_echo_c++/CMakeLists.txt
@@ -2,6 +2,62 @@ cmake_minimum_required(VERSION 2.8.10)
 project(multi_threaded_echo_c++ C CXX)
 
 option(EXAMPLE_LINK_SO "Whether examples are linked dynamically" OFF)
+option(WITH_DPDK "Whether to build with dpdk" ON)
+set(DPDK_DIR "/usr/local/dpdk" CACHE STRING "DPDK dir")
+
+if(WITH_DPDK)
+    set(BRPC_WITH_DPDK 1)
+    set(WITH_DPDK_VAL "1")
+else()
+    set(BRPC_WITH_DPDK 0)
+    set(WITH_DPDK_VAL "0")
+endif()
+
+
+if(WITH_DPDK)
+
+include_directories(
+    ${DPDK_DIR}/include
+)
+
+link_directories(
+    ${DPDK_DIR}/lib
+)
+
+set(DPDK_LIBS
+ -Wl,--disable-new-dtags
+ -Wl,--push-state
+ -Wl,--whole-archive
+ -Wl,--no-as-needed
+ -Wl,--start-group
+ rte_bus_pci
+ rte_cryptodev
+ rte_dmadev
+ rte_eal
+ rte_ethdev
+ rte_hash
+ rte_kvargs
+ rte_mbuf
+ rte_mempool
+ rte_mempool_ring
+ rte_net
+ rte_pci
+ rte_power
+ rte_rcu
+ rte_ring
+ rte_telemetry
+ rte_vhost
+ rte_meter
+ rte_timer
+ rte_stack
+ -Wl,--end-group
+ -Wl,--no-whole-archive
+ -Wl,--pop-state
+)
+
+link_libraries(${DPDK_LIBS})
+endif(WITH_DPDK)
+
 
 execute_process(
     COMMAND bash -c "find ${PROJECT_SOURCE_DIR}/../.. -type d -regex \".*output/include$\" | head -n1 | xargs dirname | tr -d '\n'"
@@ -27,9 +83,9 @@ if (NOT THRIFTNB_LIB)
     set(THRIFTNB_LIB "")
 endif()
 
-find_path(GPERFTOOLS_INCLUDE_DIR NAMES gperftools/heap-profiler.h)
-find_library(GPERFTOOLS_LIBRARIES NAMES tcmalloc_and_profiler)
-include_directories(${GPERFTOOLS_INCLUDE_DIR})
+#find_path(GPERFTOOLS_INCLUDE_DIR NAMES gperftools/heap-profiler.h)
+#find_library(GPERFTOOLS_LIBRARIES NAMES tcmalloc_and_profiler)
+#include_directories(${GPERFTOOLS_INCLUDE_DIR})
 
 find_path(BRPC_INCLUDE_PATH NAMES brpc/server.h)
 if(EXAMPLE_LINK_SO)
@@ -67,9 +123,9 @@ if(CMAKE_SYSTEM_NAME STREQUAL "Darwin")
     endif()
 endif()
 
-set(CMAKE_CPP_FLAGS "${DEFINE_CLOCK_GETTIME} -DGFLAGS_NS=${GFLAGS_NS}")
+set(CMAKE_CPP_FLAGS "${DEFINE_CLOCK_GETTIME} -mssse3 -DBRPC_WITH_DPDK=${WITH_DPDK_VAL} -DGFLAGS_NS=${GFLAGS_NS}")
 set(CMAKE_CXX_FLAGS "${CMAKE_CPP_FLAGS} -DNDEBUG -O2 -D__const__= -pipe -W -Wall -Wno-unused-parameter -fPIC -fno-omit-frame-pointer")
-set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -DBRPC_ENABLE_CPU_PROFILER")
+#set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -DBRPC_ENABLE_CPU_PROFILER")
 
 if(CMAKE_VERSION VERSION_LESS "3.1.3")
     if(CMAKE_CXX_COMPILER_ID STREQUAL "GNU")
@@ -129,5 +185,7 @@ endif()
 add_executable(multi_threaded_echo_client client.cpp ${PROTO_SRC} ${PROTO_HEADER})
 add_executable(multi_threaded_echo_server server.cpp ${PROTO_SRC} ${PROTO_HEADER})
 
-target_link_libraries(multi_threaded_echo_client ${BRPC_LIB} ${DYNAMIC_LIB} ${GPERFTOOLS_LIBRARIES})
-target_link_libraries(multi_threaded_echo_server ${BRPC_LIB} ${DYNAMIC_LIB} ${GPERFTOOLS_LIBRARIES})
+target_link_libraries(multi_threaded_echo_client ${BRPC_LIB} ${DYNAMIC_LIB})
+# ${GPERFTOOLS_LIBRARIES})
+target_link_libraries(multi_threaded_echo_server ${BRPC_LIB} ${DYNAMIC_LIB})
+# ${GPERFTOOLS_LIBRARIES})
diff --git a/example/multi_threaded_echo_c++/server.cpp b/example/multi_threaded_echo_c++/server.cpp
index 622f003c..52e5e9b1 100644
--- a/example/multi_threaded_echo_c++/server.cpp
+++ b/example/multi_threaded_echo_c++/server.cpp
@@ -19,6 +19,16 @@
 #include <brpc/server.h>
 #include "echo.pb.h"
 
+#if BRPC_WITH_DPDK
+#include <rte_eal.h>
+#include <rte_errno.h>
+#include <rte_thread.h>
+#include <rte_malloc.h>
+#endif
+
+#include <err.h>
+
+DEFINE_bool(use_dpdk_malloc, true, "use dpdk malloc");
 DEFINE_bool(echo_attachment, true, "Echo attachment as well");
 DEFINE_int32(port, 8002, "TCP Port of this server");
 DEFINE_int32(idle_timeout_s, -1, "Connection will be closed if there is no "
@@ -53,6 +63,60 @@ public:
 
 DEFINE_bool(h, false, "print help information");
 
+#if BRPC_WITH_DPDK
+
+void
+unaffinitize_thread(void)
+{
+    rte_cpuset_t new_cpuset;
+    long num_cores, i;
+
+    CPU_ZERO(&new_cpuset);
+
+    num_cores = sysconf(_SC_NPROCESSORS_CONF);
+
+    /* Create a mask containing all CPUs */
+    for (i = 0; i < num_cores; i++) {
+         CPU_SET(i, &new_cpuset);
+    }
+    rte_thread_set_affinity(&new_cpuset);
+}
+
+void* dpdk_mem_allocate(size_t sz)
+{
+    /* rte_malloc seems fast enough, otherwise we need to use mempool */
+    return rte_malloc("iobuf", sz, 64);
+}
+                               
+void dpdk_mem_free(void* p)
+{
+    rte_free(p);
+}
+
+void dpdk_init(int argc, char **argv)
+{
+    char *eal_argv[] = {argv[0], (char *)"--in-memory", NULL};
+
+    if (rte_eal_init(2, eal_argv) == -1) {
+        errx(1, "rte_eal_init: %s", rte_strerror(rte_errno));
+    }
+
+    /* !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+     * Following is important. Above, we didn't specify dpdk runs on every cpu,
+     * thus dpdk will default bind our thread to first cpu, and the cpu mask
+     * is inherited by pthread_create(), causes every thread in future bind to
+     * same cpu! This causes big performance problem!
+     * !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+     */
+    unaffinitize_thread();
+
+    // make iobuf use dpdk malloc & free
+    butil::iobuf::set_blockmem_allocate_and_deallocate(dpdk_mem_allocate, 
+        	dpdk_mem_free);
+}
+
+#endif
+
 int main(int argc, char* argv[]) {
     std::string help_str = "dummy help infomation";
     GFLAGS_NS::SetUsageMessage(help_str);
@@ -65,6 +129,11 @@ int main(int argc, char* argv[]) {
         return 0;
     }
 
+#if BRPC_WITH_DPDK
+    if (FLAGS_use_dpdk_malloc)
+	dpdk_init(argc, argv);
+#endif
+
     // Generally you only need one Server.
     brpc::Server server;
 
diff --git a/src/bthread/rwlock_v2.cpp b/src/bthread/rwlock_v2.cpp
new file mode 100644
index 00000000..3c128758
--- /dev/null
+++ b/src/bthread/rwlock_v2.cpp
@@ -0,0 +1,399 @@
+// bthread rwlock
+// Copyright (c) 2022 Netease, Inc.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+// Author: (yfxu@netease)
+
+#include "butil/atomicops.h"
+#include "butil/macros.h"                        // BAIDU_CASSERT
+#include "bthread/rwlock_v2.h"
+#include "bthread/mutex.h"
+#include "bthread/condition_variable.h"
+#include "bthread/task_group.h"
+
+#define RWLOCK_WRITE_OWNER     0x80000000U
+#define RWLOCK_WRITE_WAITERS   0x40000000U
+#define RWLOCK_READ_WAITERS    0x20000000U
+#define RWLOCK_MAX_READERS     0x1fffffffU
+#define RWLOCK_READER_COUNT(c) ((c) & RWLOCK_MAX_READERS)
+
+#define PREFER_READER(rwlock) ((rwlock)->rw_flags != 0)
+
+namespace bthread {
+
+extern BAIDU_THREAD_LOCAL TaskGroup* tls_task_group; 
+
+namespace v2 {
+static inline int
+cas_acq_int(volatile int *dst, int expect, int src)
+{
+    return __atomic_compare_exchange_n(dst, &expect, src, 0,
+                __ATOMIC_ACQUIRE, __ATOMIC_RELAXED);
+}
+
+static inline int
+cas_rel_int(volatile int *dst, int expect, int src)
+{
+    return __atomic_compare_exchange_n(dst, &expect, src, 0,
+                __ATOMIC_RELEASE, __ATOMIC_RELAXED);
+}
+
+int
+bthread_rwlockattr_init(bthread_rwlockattr_t *attr)
+{
+    attr->lockkind = BTHREAD_RWLOCK_DEFAULT_NP;
+    return 0;
+}
+
+int
+bthread_rwlockattr_destroy(bthread_rwlockattr_t *attr)
+{
+    return 0;
+}
+
+int
+bthread_rwlockattr_getkind_np(
+    const bthread_rwlockattr_t* __restrict attr, int *__restrict pref)
+{
+    *pref = attr->lockkind;
+    return 0;
+}
+
+int
+bthread_rwlockattr_setkind_np(bthread_rwlockattr_t *attr,
+                                          int pref)
+{
+    switch(pref) {
+    case BTHREAD_RWLOCK_PREFER_WRITER_NP:
+    case BTHREAD_RWLOCK_PREFER_READER_NP:
+    case BTHREAD_RWLOCK_PREFER_WRITER_NONRECURSIVE_NP:
+         attr->lockkind = pref;
+         return 0;
+    }
+    return EINVAL;
+}
+
+static inline void
+rwlock_set_owner(bthread_rwlock_t *rwlock)
+{
+    TaskGroup* g = tls_task_group;
+    if (NULL == g || g->is_current_pthread_task()) {
+        rwlock->rw_task = NULL;
+        rwlock->rw_thread = pthread_self();
+    } else {
+        rwlock->rw_task = g->current_task();
+        rwlock->rw_thread = 0;
+    }
+}
+
+static inline int 
+rwlock_check_owner(bthread_rwlock_t *rwlock)
+{
+    TaskGroup* g = tls_task_group;
+    if (NULL == g || g->is_current_pthread_task()) {
+        if (rwlock->rw_thread != pthread_self())
+            return -1; 
+    } else {
+        if (rwlock->rw_task != g->current_task())
+            return -1;
+    }
+    return 0;
+}
+
+static inline void
+rwlock_clear_owner(bthread_rwlock_t *rwlock)
+{
+    rwlock->rw_task = NULL;
+    rwlock->rw_thread = 0;
+}
+
+static inline int
+rwlock_tryrdlock(bthread_rwlock_t *rwlock)
+{
+    int state;
+    int wrflags;
+
+    wrflags = RWLOCK_WRITE_OWNER;
+    if (!PREFER_READER(rwlock))
+        wrflags |= RWLOCK_WRITE_WAITERS;
+    state = rwlock->rw_state;
+    while (!(state & wrflags)) {
+        if (RWLOCK_READER_COUNT(state) == RWLOCK_MAX_READERS)
+            return (EAGAIN);
+        if (cas_acq_int(&rwlock->rw_state, state, state + 1))
+            return (0);
+        state = rwlock->rw_state;
+    }
+
+    return (EBUSY);
+}  	
+
+static int
+rwlock_rdwait(bthread_rwlock_t *rwlock, const struct timespec *abstime)
+{
+    int state;
+    int wrflags;
+    int error = 0;
+
+    wrflags = RWLOCK_WRITE_OWNER;
+    if (!PREFER_READER(rwlock))
+        wrflags |= RWLOCK_WRITE_WAITERS;
+
+    bthread_mutex_lock(&rwlock->rw_mutex);
+    while (error == 0) {
+        state = rwlock->rw_state;
+        if ((state & wrflags) == 0)
+            break;
+        if ((state & RWLOCK_READ_WAITERS) == 0) {
+            /* Set reader-waiting bit */
+            if (! cas_acq_int(&rwlock->rw_state, state,
+                        state | RWLOCK_READ_WAITERS))
+                continue;
+        }
+        rwlock->rw_blocked_readers++;
+        if (abstime != NULL)
+            error = bthread_cond_timedwait(&rwlock->rw_cv_reader,
+                    &rwlock->rw_mutex, abstime);
+        else
+            error = bthread_cond_wait(&rwlock->rw_cv_reader,
+                    &rwlock->rw_mutex);
+
+        if (--rwlock->rw_blocked_readers == 0) {
+            /* it is lastest reader thread, clear waiting bit. */
+            for (;;) {
+                state = rwlock->rw_state;
+                if (cas_acq_int(&rwlock->rw_state,
+                            state, state & ~RWLOCK_READ_WAITERS))
+                    break;
+            }
+        }
+    }
+    bthread_mutex_unlock(&rwlock->rw_mutex);
+    return (error);
+}
+
+static inline int
+rwlock_trywrlock(bthread_rwlock_t *rwlock)
+{
+    int state;
+
+    state = rwlock->rw_state;
+    while (!(state & RWLOCK_WRITE_OWNER) && RWLOCK_READER_COUNT(state) == 0) {
+        if (cas_acq_int(&rwlock->rw_state, state,
+                    state | RWLOCK_WRITE_OWNER)) {
+            rwlock_set_owner(rwlock);
+            return (0);
+        }
+        state = rwlock->rw_state;
+    }
+
+    return (EBUSY);
+}
+
+static int
+rwlock_wrwait(bthread_rwlock_t *rwlock, const struct timespec *abstime)
+{
+    int state;
+    int error = 0;
+
+    bthread_mutex_lock(&rwlock->rw_mutex);
+    while (error == 0) {
+        state = rwlock->rw_state;
+        if (!(state & RWLOCK_WRITE_OWNER) && RWLOCK_READER_COUNT(state) == 0)
+            break;
+        if ((state & RWLOCK_WRITE_WAITERS) == 0) {
+            if (!cas_acq_int(&rwlock->rw_state, state,
+                        state | RWLOCK_WRITE_WAITERS))
+                continue;
+        }
+        rwlock->rw_blocked_writers++;
+        if (abstime != NULL) {
+            error = bthread_cond_timedwait(&rwlock->rw_cv_writer,
+                    &rwlock->rw_mutex, abstime);
+        } else {
+            error = bthread_cond_wait(&rwlock->rw_cv_writer,
+                    &rwlock->rw_mutex);
+        }
+        if (--rwlock->rw_blocked_writers == 0) {
+            /* it is lastest writer thread, clear waiting bit. */
+            for (;;) {
+                state = rwlock->rw_state;
+                if (cas_acq_int(&rwlock->rw_state,
+                            state, state & ~RWLOCK_WRITE_WAITERS))
+                    break;
+            }
+        }
+    }
+    bthread_mutex_unlock(&rwlock->rw_mutex);
+    return (error);
+}
+
+int
+bthread_rwlock_timedrdlock(bthread_rwlock_t *rwlock,
+    const struct timespec *abstime)
+{
+    int error;
+
+    /*
+     * POSIX said the validity of the abstimeout parameter need
+     * not be checked if the lock can be immediately acquired.
+     */
+    error = rwlock_tryrdlock(rwlock);
+    if (error == 0)
+        return (error);
+
+    for (;;) {
+        error = rwlock_rdwait(rwlock, abstime);
+        if (rwlock_tryrdlock(rwlock) == 0) {
+            error = 0;
+            break;
+        } else if (error != 0)
+            break;
+    }
+    return (error);
+}
+
+int
+bthread_rwlock_timedwrlock(bthread_rwlock_t *rwlock,
+    const struct timespec *abstime)
+{
+    int error;
+
+    error = rwlock_trywrlock(rwlock);
+    if (error == 0)
+        return (error);
+
+    for (;;) {
+        error = rwlock_wrwait(rwlock, abstime);
+        if (rwlock_trywrlock(rwlock) == 0) {
+            error = 0;
+            break;
+        } else if (error != 0)
+            break;
+    }
+    return (error);
+}
+
+int
+bthread_rwlock_unlock(bthread_rwlock_t *rwlock)
+{
+    int state;
+    int broadcast;
+    bthread_cond_t *q;
+
+    state = rwlock->rw_state;
+    if (state & RWLOCK_WRITE_OWNER) {
+        if (rwlock_check_owner(rwlock))
+            return (EPERM);
+        rwlock_clear_owner(rwlock);
+        for (;;) {
+            if (cas_rel_int(&rwlock->rw_state, state,
+                        state & ~RWLOCK_WRITE_OWNER))
+                break;
+            state = rwlock->rw_state;
+            if (!(state & RWLOCK_WRITE_OWNER))
+                return (EPERM);
+        }
+    } else if (RWLOCK_READER_COUNT(state) != 0) {
+        for (;;) {
+            if (cas_rel_int(&rwlock->rw_state, state,
+                        state - 1))
+                break;
+            state = rwlock->rw_state;
+            if (RWLOCK_READER_COUNT(state) == 0)
+                return (EPERM);
+        }
+        if (RWLOCK_READER_COUNT(state) > 1)
+            return (0);
+    } else {
+        return (EPERM);
+    }
+    q = NULL;
+    broadcast = 0;
+    if (!PREFER_READER(rwlock)) {
+        if (state & RWLOCK_WRITE_WAITERS) {
+            broadcast = 0;
+            q = &rwlock->rw_cv_writer;
+        } else if (state & RWLOCK_READ_WAITERS) {
+            broadcast = 1;
+            q = &rwlock->rw_cv_reader;
+        }
+    } else {
+        if (state & RWLOCK_READ_WAITERS) {
+            broadcast = 1;
+            q = &rwlock->rw_cv_reader;
+        } else if (state & RWLOCK_WRITE_WAITERS) {
+            broadcast = 0;
+            q = &rwlock->rw_cv_writer;
+        }
+    }
+
+    if (q != NULL) {
+        bthread_mutex_lock(&rwlock->rw_mutex);
+        if (broadcast)
+            bthread_cond_broadcast(q);
+        else
+            bthread_cond_signal(q);
+        bthread_mutex_unlock(&rwlock->rw_mutex);
+    }
+
+    return (0);
+}
+
+int
+bthread_rwlock_tryrdlock(bthread_rwlock_t *rwlock)
+{
+    return rwlock_tryrdlock(rwlock);
+}
+
+int
+bthread_rwlock_trywrlock(bthread_rwlock_t *rwlock)
+{
+    return rwlock_trywrlock(rwlock);
+}
+
+int
+bthread_rwlock_rdlock(bthread_rwlock_t *rwlock)
+{
+    return bthread_rwlock_timedrdlock(rwlock, NULL);
+}
+
+int
+bthread_rwlock_wrlock(bthread_rwlock_t *rwlock)
+{
+    return bthread_rwlock_timedwrlock(rwlock, NULL);
+}
+
+int
+bthread_rwlock_init(bthread_rwlock_t *rwlock, const bthread_rwlockattr_t *attr)
+{
+    memset(rwlock, 0, sizeof(bthread_rwlock_t));
+    rwlock->rw_flags = attr ?
+        (attr->lockkind == BTHREAD_RWLOCK_PREFER_WRITER_NONRECURSIVE_NP) : 0;
+    bthread_mutex_init(&rwlock->rw_mutex, NULL);
+    bthread_cond_init(&rwlock->rw_cv_reader, NULL);
+    bthread_cond_init(&rwlock->rw_cv_writer, NULL);
+    return (0);
+}
+
+int
+bthread_rwlock_destroy(bthread_rwlock_t *rwlock)
+{
+    bthread_mutex_destroy(&rwlock->rw_mutex);
+    bthread_cond_destroy(&rwlock->rw_cv_reader);
+    bthread_cond_destroy(&rwlock->rw_cv_writer);
+    return (0);
+}
+} // v2
+} // namespace bthread
diff --git a/src/bthread/rwlock_v2.h b/src/bthread/rwlock_v2.h
new file mode 100644
index 00000000..e9d990e8
--- /dev/null
+++ b/src/bthread/rwlock_v2.h
@@ -0,0 +1,181 @@
+// bthread rwlock
+// Copyright (c) 2022 Netease, Inc.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+// Author: (yfxu@netease)
+
+#ifndef BTHREAD_RW_LOCKV2_H
+#define BTHREAD_RW_LOCKV2_H
+
+#include "bthread/types.h"
+#include "butil/errno.h"
+#include "butil/logging.h"
+
+enum
+{
+    BTHREAD_RWLOCK_PREFER_READER_NP,
+    BTHREAD_RWLOCK_PREFER_WRITER_NP, // ignored by bthread_rwlock_v2_t
+    BTHREAD_RWLOCK_PREFER_WRITER_NONRECURSIVE_NP,
+    BTHREAD_RWLOCK_DEFAULT_NP = BTHREAD_RWLOCK_PREFER_READER_NP
+}; 
+
+namespace bthread {
+namespace v2 {
+
+typedef struct {
+    int lockkind;
+} bthread_rwlockattr_t;
+
+typedef struct bthread_rwlock {
+    volatile int    rw_state;
+    int             rw_flags;
+    bthread_mutex_t rw_mutex;
+    bthread_cond_t  rw_cv_reader;
+    bthread_cond_t  rw_cv_writer;
+    int             rw_blocked_readers;
+    int             rw_blocked_writers;
+    pthread_t       rw_thread;
+    void            *rw_task;
+} bthread_rwlock_t;
+
+// -------------------------------------------
+// Functions for handling read-write locks.
+// -------------------------------------------
+
+/* Initialize attribute object ATTR with default values.  */
+extern int bthread_rwlockattr_init(bthread_rwlockattr_t *attr);
+
+/* Destroy attribute object ATTR.  */
+extern int bthread_rwlockattr_destroy(bthread_rwlockattr_t *attr);
+
+/* Return current setting of reader/writer preference.  */ 
+extern int bthread_rwlockattr_getkind_np(
+    const bthread_rwlockattr_t* __restrict attr, int *__restrict pref);
+
+/* Set reader/write preference.  */
+extern int bthread_rwlockattr_setkind_np(bthread_rwlockattr_t *attr,
+                                          int pref);
+
+// Initialize read-write lock `rwlock' using attributes `attr', or use
+// the default values if later is NULL.
+extern int bthread_rwlock_init(bthread_rwlock_t* __restrict rwlock,
+                               const bthread_rwlockattr_t* __restrict attr);
+
+// Destroy read-write lock `rwlock'.
+extern int bthread_rwlock_destroy(bthread_rwlock_t* rwlock);
+
+// Acquire read lock for `rwlock'.
+extern int bthread_rwlock_rdlock(bthread_rwlock_t* rwlock);
+
+// Try to acquire read lock for `rwlock'.
+extern int bthread_rwlock_tryrdlock(bthread_rwlock_t* rwlock);
+
+// Try to acquire read lock for `rwlock' or return after specfied time.
+extern int bthread_rwlock_timedrdlock(bthread_rwlock_t* __restrict rwlock,
+                                      const struct timespec* __restrict abstime);
+
+// Acquire write lock for `rwlock'.
+extern int bthread_rwlock_wrlock(bthread_rwlock_t* rwlock);
+
+// Try to acquire write lock for `rwlock'.
+extern int bthread_rwlock_trywrlock(bthread_rwlock_t* rwlock);
+
+// Try to acquire write lock for `rwlock' or return after specfied time.
+extern int bthread_rwlock_timedwrlock(bthread_rwlock_t* __restrict rwlock,
+                                      const struct timespec* __restrict abstime);
+
+// Unlock `rwlock'.
+extern int bthread_rwlock_unlock(bthread_rwlock_t* rwlock);
+
+
+// ---------------------------------------------------
+// Functions for handling read-write lock attributes.
+// ---------------------------------------------------
+
+// Initialize attribute object `attr' with default values.
+extern int bthread_rwlockattr_init(bthread_rwlockattr_t* attr);
+
+// Destroy attribute object `attr'.
+extern int bthread_rwlockattr_destroy(bthread_rwlockattr_t* attr);
+
+// Return current setting of reader/writer preference.
+extern int bthread_rwlockattr_getkind_np(const bthread_rwlockattr_t* attr, int* pref);
+
+// Set reader/write preference.
+extern int bthread_rwlockattr_setkind_np(bthread_rwlockattr_t* attr, int pref);
+
+
+// Specialize std::lock_guard and std::unique_lock for bthread_rwlock_t
+
+class wlock_guard {
+public:
+    explicit wlock_guard(bthread_rwlock_t& mutex) : _pmutex(&mutex) {
+#if !defined(NDEBUG)
+        const int rc = bthread_rwlock_wrlock(_pmutex);
+        if (rc) {
+            LOG(FATAL) << "Fail to lock bthread_rwlock_t=" << _pmutex << ", " << berror(rc);
+            _pmutex = NULL;
+        }
+#else
+        bthread_rwlock_wrlock(_pmutex);
+#endif // NDEBUG
+    }
+
+    ~wlock_guard() {
+#ifndef NDEBUG
+        if (_pmutex) {
+            bthread_rwlock_unlock(_pmutex);
+        }
+#else
+        bthread_rwlock_unlock(_pmutex);
+#endif
+    }
+
+private:
+    DISALLOW_COPY_AND_ASSIGN(wlock_guard);
+    bthread_rwlock_t* _pmutex;
+};
+
+class rlock_guard {
+public:
+    explicit rlock_guard(bthread_rwlock_t& mutex) : _pmutex(&mutex) {
+#if !defined(NDEBUG)
+        const int rc = bthread_rwlock_rdlock(_pmutex);
+        if (rc) {
+            LOG(FATAL) << "Fail to lock bthread_rwlock_t=" << _pmutex << ", " << berror(rc);
+            _pmutex = NULL;
+        }
+#else
+        bthread_rwlock_rdlock(_pmutex);
+#endif // NDEBUG
+    }
+
+    ~rlock_guard() {
+#ifndef NDEBUG
+        if (_pmutex) {
+            bthread_rwlock_unlock(_pmutex);
+        }
+#else
+        bthread_rwlock_unlock(_pmutex);
+#endif
+    }
+
+private:
+    DISALLOW_COPY_AND_ASSIGN(rlock_guard);
+    bthread_rwlock_t* _pmutex;
+};
+
+} // namespace v2
+} // namespace bthread
+#endif // BTHREAD_RW_LOCKV2_H
diff --git a/src/bthread/task_group.cpp b/src/bthread/task_group.cpp
index 45e2b859..f19d2313 100644
--- a/src/bthread/task_group.cpp
+++ b/src/bthread/task_group.cpp
@@ -66,6 +66,7 @@ extern void return_keytable(bthread_keytable_pool_t*, KeyTable*);
 // [Hacky] This is a special TLS set by bthread-rpc privately... to save
 // overhead of creation keytable, may be removed later.
 BAIDU_THREAD_LOCAL void* tls_unique_user_ptr = NULL;
+BAIDU_THREAD_LOCAL bool tls_iobuf_is_user;
 
 const TaskStatistics EMPTY_STAT = { 0, 0 };
 
@@ -570,6 +571,7 @@ void TaskGroup::sched_to(TaskGroup** pg, TaskMeta* next_meta) {
     // Save errno so that errno is bthread-specific.
     const int saved_errno = errno;
     void* saved_unique_user_ptr = tls_unique_user_ptr;
+    bool saved_iobuf_is_user = tls_iobuf_is_user;
 
     TaskMeta* const cur_meta = g->_cur_meta;
     const int64_t now = butil::cpuwide_time_ns();
@@ -625,6 +627,7 @@ void TaskGroup::sched_to(TaskGroup** pg, TaskMeta* next_meta) {
     // Restore errno
     errno = saved_errno;
     tls_unique_user_ptr = saved_unique_user_ptr;
+    tls_iobuf_is_user = saved_iobuf_is_user;
 
 #ifndef NDEBUG
     --g->_sched_recursive_guard;
diff --git a/src/butil/iobuf.cpp b/src/butil/iobuf.cpp
index 2219ff8b..b3126f6e 100644
--- a/src/butil/iobuf.cpp
+++ b/src/butil/iobuf.cpp
@@ -34,9 +34,36 @@
 #include "butil/fd_guard.h"                 // butil::fd_guard
 #include "butil/iobuf.h"
 
+namespace bthread
+{
+    extern BAIDU_THREAD_LOCAL bool tls_iobuf_is_user;
+}
+
+namespace {
+
+class UserBufGuard {
+    bool old;
+    UserBufGuard(const UserBufGuard &) = delete;
+    void operator=(const UserBufGuard &) = delete;
+public:
+    UserBufGuard(bool v) {
+        old = bthread::tls_iobuf_is_user;
+        bthread::tls_iobuf_is_user = v;
+    }
+    ~UserBufGuard()
+    {
+        bthread::tls_iobuf_is_user = old;
+    }
+};
+}
+
 namespace butil {
 namespace iobuf {
 
+bool iobuf_is_user() {
+    return bthread::tls_iobuf_is_user;
+}
+
 typedef ssize_t (*iov_function)(int fd, const struct iovec *vector,
                                    int count, off_t offset);
 
@@ -96,7 +123,7 @@ static ssize_t sys_pwritev(int fd, const struct iovec *vector,
     return syscall(SYS_pwritev, fd, vector, count, offset);
 }
 
-inline iov_function get_preadv_func() {
+inline iov_function get_sys_preadv_func() {
     butil::fd_guard fd(open("/dev/zero", O_RDONLY));
     if (fd < 0) {
         PLOG(WARNING) << "Fail to open /dev/zero";
@@ -116,7 +143,7 @@ inline iov_function get_preadv_func() {
     return sys_preadv;
 }
 
-inline iov_function get_pwritev_func() {
+inline iov_function get_sys_pwritev_func() {
     butil::fd_guard fd(open("/dev/null", O_WRONLY));
     if (fd < 0) {
         PLOG(ERROR) << "Fail to open /dev/null";
@@ -141,16 +168,71 @@ inline iov_function get_pwritev_func() {
 #warning "We don't check whether the kernel supports SYS_preadv or SYS_pwritev " \
          "when the arch is not X86_64, use user space preadv/pwritev directly"
 
-inline iov_function get_preadv_func() {
+inline iov_function get_sys_preadv_func() {
     return user_preadv;
 }
 
-inline iov_function get_pwritev_func() {
+inline iov_function get_sys_pwritev_func() {
     return user_pwritev;
 }
 
 #endif  // ARCH_CPU_X86_64
 
+iov_function external_preadv;
+iov_function external_pwritev;
+iov_seq_function external_readv;
+iov_seq_function external_writev;
+
+inline iov_function get_preadv_func() {
+    static iov_function sys_preadv_func = get_sys_preadv_func();
+    if (external_preadv)
+        return external_preadv;
+    return sys_preadv_func;
+}
+
+inline iov_function get_pwritev_func() {
+    static iov_function sys_pwritev_func = get_sys_pwritev_func();
+    if (external_pwritev)
+        return external_pwritev;
+    return sys_pwritev_func;
+}
+
+inline iov_seq_function get_readv_func() {
+    if (external_readv)
+        return external_readv;
+    return readv;
+}
+
+inline iov_seq_function get_writev_func() {
+    if (external_writev)
+        return external_writev;
+    return writev;
+}
+
+int set_external_io_funcs(struct iobuf_io_funcs funcs)
+{
+    if (funcs.iof_preadv == NULL ||
+            funcs.iof_pwritev == NULL ||
+            funcs.iof_readv == NULL ||
+            funcs.iof_writev == NULL) {
+        return -1;
+    }
+
+    external_pwritev = funcs.iof_pwritev;
+    external_preadv = funcs.iof_preadv;
+    external_writev = funcs.iof_writev;
+    external_readv = funcs.iof_readv;
+    return 1;
+}
+
+void get_external_io_funcs(struct iobuf_io_funcs *funcs)
+{
+    funcs->iof_pwritev = external_pwritev;
+    funcs->iof_preadv = external_preadv;
+    funcs->iof_writev = external_writev;
+    funcs->iof_readv = external_readv;
+}
+
 inline void* cp(void *__restrict dest, const void *__restrict src, size_t n) {
     // memcpy in gcc 4.8 seems to be faster enough.
     return memcpy(dest, src, n);
@@ -166,6 +248,13 @@ void reset_blockmem_allocate_and_deallocate() {
     blockmem_deallocate = ::free;
 }
 
+void set_blockmem_allocate_and_deallocate(blockmem_allocate_t a,
+        blockmem_deallocate_t f)
+{
+    blockmem_allocate = a;
+    blockmem_deallocate = f;
+}
+
 butil::static_atomic<size_t> g_nblock = BUTIL_STATIC_ATOMIC_INIT(0);
 butil::static_atomic<size_t> g_blockmem = BUTIL_STATIC_ATOMIC_INIT(0);
 butil::static_atomic<size_t> g_newbigview = BUTIL_STATIC_ATOMIC_INIT(0);
@@ -271,6 +360,9 @@ struct IOBuf::Block {
 
     bool full() const { return size >= cap; }
     size_t left_space() const { return cap - size; }
+    bool user_buf() const {
+        return !!(flags & IOBUF_BLOCK_FLAGS_USER_DATA);
+    }
 };
 
 namespace iobuf {
@@ -947,15 +1039,19 @@ ssize_t IOBuf::pcut_into_file_descriptor(int fd, off_t offset, size_t size_hint)
     struct iovec vec[nref];
     size_t nvec = 0;
     size_t cur_len = 0;
+    bool user_buf = false;
 
     do {
         IOBuf::BlockRef const& r = _ref_at(nvec);
+        user_buf |= r.block->user_buf();
         vec[nvec].iov_base = r.block->data + r.offset;
         vec[nvec].iov_len = r.length;
         ++nvec;
         cur_len += r.length;
     } while (nvec < nref && cur_len < size_hint);
 
+    UserBufGuard ug(user_buf);
+
     ssize_t nw = 0;
 
     if (offset >= 0) {
@@ -978,15 +1074,19 @@ ssize_t IOBuf::cut_into_writer(IWriter* writer, size_t size_hint) {
     struct iovec vec[nref];
     size_t nvec = 0;
     size_t cur_len = 0;
+    bool user_buf = false;
 
     do {
         IOBuf::BlockRef const& r = _ref_at(nvec);
+        user_buf |= r.block->user_buf();
         vec[nvec].iov_base = r.block->data + r.offset;
         vec[nvec].iov_len = r.length;
         ++nvec;
         cur_len += r.length;
     } while (nvec < nref && cur_len < size_hint);
 
+    UserBufGuard ug(user_buf);
+
     const ssize_t nw = writer->WriteV(vec, nvec);
     if (nw > 0) {
         pop_front(nw);
@@ -1073,11 +1173,13 @@ ssize_t IOBuf::pcut_multiple_into_file_descriptor(
     }
     struct iovec vec[IOBUF_IOV_MAX];
     size_t nvec = 0;
+    bool user_buf = false;
     for (size_t i = 0; i < count; ++i) {
         const IOBuf* p = pieces[i];
         const size_t nref = p->_ref_num();
         for (size_t j = 0; j < nref && nvec < IOBUF_IOV_MAX; ++j, ++nvec) {
             IOBuf::BlockRef const& r = p->_ref_at(j);
+            user_buf |= r.block->user_buf();
             vec[nvec].iov_base = r.block->data + r.offset;
             vec[nvec].iov_len = r.length;
         }
@@ -1113,16 +1215,20 @@ ssize_t IOBuf::cut_multiple_into_writer(
     }
     struct iovec vec[IOBUF_IOV_MAX];
     size_t nvec = 0;
+    bool user_buf = false;
     for (size_t i = 0; i < count; ++i) {
         const IOBuf* p = pieces[i];
         const size_t nref = p->_ref_num();
         for (size_t j = 0; j < nref && nvec < IOBUF_IOV_MAX; ++j, ++nvec) {
             IOBuf::BlockRef const& r = p->_ref_at(j);
+            user_buf |= r.block->user_buf();
             vec[nvec].iov_base = r.block->data + r.offset;
             vec[nvec].iov_len = r.length;
         }
     }
 
+    UserBufGuard ug(user_buf);
+
     const ssize_t nw = writer->WriteV(vec, nvec);
     if (nw <= 0) {
         return nw;
@@ -1578,6 +1684,8 @@ ssize_t IOPortal::pappend_from_file_descriptor(
     size_t space = 0;
     Block* prev_p = NULL;
     Block* p = _block;
+    bool user_buf = false;
+
     // Prepare at most MAX_APPEND_IOVEC blocks or space of blocks >= max_count
     do {
         if (p == NULL) {
@@ -1592,6 +1700,7 @@ ssize_t IOPortal::pappend_from_file_descriptor(
                 _block = p;
             }
         }
+        user_buf |= p->user_buf();
         vec[nvec].iov_base = p->data + p->size;
         vec[nvec].iov_len = std::min(p->left_space(), max_count - space);
         space += vec[nvec].iov_len;
@@ -1603,6 +1712,8 @@ ssize_t IOPortal::pappend_from_file_descriptor(
         p = p->portal_next;
     } while (1);
 
+    UserBufGuard ug(user_buf);
+
     ssize_t nr = 0;
     if (offset < 0) {
         nr = readv(fd, vec, nvec);
@@ -1639,6 +1750,7 @@ ssize_t IOPortal::append_from_reader(IReader* reader, size_t max_count) {
     size_t space = 0;
     Block* prev_p = NULL;
     Block* p = _block;
+    bool user_buf = false;
     // Prepare at most MAX_APPEND_IOVEC blocks or space of blocks >= max_count
     do {
         if (p == NULL) {
@@ -1653,6 +1765,7 @@ ssize_t IOPortal::append_from_reader(IReader* reader, size_t max_count) {
                 _block = p;
             }
         }
+        user_buf |= p->user_buf();
         vec[nvec].iov_base = p->data + p->size;
         vec[nvec].iov_len = std::min(p->left_space(), max_count - space);
         space += vec[nvec].iov_len;
@@ -1664,6 +1777,8 @@ ssize_t IOPortal::append_from_reader(IReader* reader, size_t max_count) {
         p = p->portal_next;
     } while (1);
 
+    UserBufGuard ug(user_buf);
+
     const ssize_t nr = reader->ReadV(vec, nvec);
     if (nr <= 0) {  // -1 or 0
         if (empty()) {
diff --git a/src/butil/iobuf.h b/src/butil/iobuf.h
index 13474367..4dce2fe3 100644
--- a/src/butil/iobuf.h
+++ b/src/butil/iobuf.h
@@ -671,6 +671,34 @@ private:
     const butil::IOBuf* _buf;
 };
 
+namespace iobuf {
+
+typedef void* (*blockmem_allocate_t)(size_t);
+typedef void  (*blockmem_deallocate_t)(void*);
+
+typedef ssize_t (*iov_function)(int fd, const struct iovec *vector,
+                                   int count, off_t offset);
+
+typedef ssize_t (*iov_seq_function)(int fd, const struct iovec *vector,
+                                    int count);
+
+struct iobuf_io_funcs {
+	iov_function iof_preadv;
+	iov_function iof_pwritev;
+	iov_seq_function iof_readv;
+	iov_seq_function iof_writev;
+};
+
+void set_blockmem_allocate_and_deallocate(blockmem_allocate_t,
+	blockmem_deallocate_t);
+
+int set_external_io_funcs(struct iobuf_io_funcs funcs);
+
+void get_external_io_funcs(struct iobuf_io_funcs *funcs);
+
+bool iobuf_is_user();
+
+}  // namespace iobuf
 }  // namespace butil
 
 // Specialize std::swap for IOBuf
diff --git a/test/bthread_brpc_rwlockv2_unittest.cpp b/test/bthread_brpc_rwlockv2_unittest.cpp
new file mode 100644
index 00000000..98de891f
--- /dev/null
+++ b/test/bthread_brpc_rwlockv2_unittest.cpp
@@ -0,0 +1,199 @@
+// Copyright (c) 2020 Bigo, Inc.
+// Author: HeTao (hetao@bigo.sg)
+// Date: Jan 06 2020
+
+#include <gtest/gtest.h>
+#include "butil/compat.h"
+#include "butil/time.h"
+#include "butil/macros.h"
+#include "butil/string_printf.h"
+#include "butil/logging.h"
+#include "bthread/bthread.h"
+#include "bthread/butex.h"
+#include "bthread/task_control.h"
+#include "bthread/rwlock_v2.h"
+#include "butil/gperftools_profiler.h"
+
+#include <stdlib.h>
+
+namespace {
+
+TEST(RwlockTest, sanity) {
+    bthread::v2::bthread_rwlock_t m;
+    ASSERT_EQ(0, bthread_rwlock_init(&m, NULL));
+    ASSERT_EQ(0, bthread_rwlock_rdlock(&m));
+    ASSERT_EQ(0, bthread_rwlock_unlock(&m));
+    ASSERT_EQ(0, bthread_rwlock_wrlock(&m));
+    ASSERT_EQ(0, bthread_rwlock_unlock(&m));
+    ASSERT_EQ(0, bthread_rwlock_destroy(&m));
+}
+
+
+
+bool g_started = false;
+bool g_stopped = false;
+
+template <typename Rwlock>
+struct BAIDU_CACHELINE_ALIGNMENT PerfArgs {
+    Rwlock* rwlock;
+    int64_t counter;
+    int64_t elapse_ns;
+    bool ready;
+    int32_t op_type;   /*0 for read,1 for write*/
+
+    PerfArgs() : rwlock(NULL), counter(0), elapse_ns(0), ready(false), op_type(0) {}
+};
+
+template <typename Rwlock>
+void* add_with_rwlock(void* void_arg) {
+    PerfArgs<Rwlock>* args = (PerfArgs<Rwlock>*)void_arg;
+    args->ready = true;
+    butil::Timer t;
+    while (!g_stopped) {
+        if (g_started) {
+            break;
+        }
+        bthread_usleep(1000);
+    }
+    t.start();
+    while (!g_stopped) {
+        if(args->op_type == 0) {
+            // args->rwlock->Rlock();
+            bthread_rwlock_rdlock(args->rwlock);
+        }
+        else {
+            // args->rwlock->Wlock();
+            bthread_rwlock_wrlock(args->rwlock);
+            }
+        // args->rwlock->Unlock();
+        bthread_rwlock_unlock(args->rwlock);
+        ++args->counter;
+    }
+    t.stop();
+    args->elapse_ns = t.n_elapsed();
+    return NULL;
+}
+
+int g_prof_name_counter = 0;
+
+template <typename Rwlock, typename ThreadId,
+         typename ThreadCreateFn, typename ThreadJoinFn>
+         void PerfTest(Rwlock* rwlock,
+                 ThreadId* /*dummy*/,
+                 int thread_num,
+                 const ThreadCreateFn& create_fn,
+                 const ThreadJoinFn& join_fn,
+                 int op_type=0 /*0 for read,1 for write*/) {
+    g_started = false;
+    g_stopped = false;
+    ThreadId threads[thread_num];
+    std::vector<PerfArgs<Rwlock> > args(thread_num);
+    for (int i = 0; i < thread_num; ++i) {
+        args[i].rwlock = rwlock;
+        args[i].op_type = op_type;
+        create_fn(&threads[i], NULL, add_with_rwlock<Rwlock>, &args[i]);
+    }
+    while (true) {
+        bool all_ready = true;
+        for (int i = 0; i < thread_num; ++i) {
+            if (!args[i].ready) {
+                all_ready = false;
+                break;
+            }
+        }
+        if (all_ready) {
+            break;
+        }
+        usleep(1000);
+    }
+    g_started = true;
+    char prof_name[32];
+    snprintf(prof_name, sizeof(prof_name), "rwlock_perf_%d.prof", ++g_prof_name_counter);
+    ProfilerStart(prof_name);
+    usleep(500 * 1000);
+    ProfilerStop();
+    g_stopped = true;
+    int64_t wait_time = 0;
+    int64_t count = 0;
+    for (int i = 0; i < thread_num; ++i) {
+        join_fn(threads[i], NULL);
+        wait_time += args[i].elapse_ns;
+        count += args[i].counter;
+    }
+    LOG(INFO) << butil::class_name<Rwlock>() << (op_type==0?" readlock ":" writelock ") << " in "
+        << ((void*)create_fn == (void*)pthread_create ? "pthread" : "bthread")
+        << " thread_num=" << thread_num
+        << " count=" << count
+        << " average_time=" << wait_time / (double)count;
+}
+
+
+TEST(RWLockTest, performance) {
+    const int thread_num = 12;
+    bthread::v2::bthread_rwlock_t brw;
+    bthread_rwlock_init(&brw, NULL);
+    //rlock
+    PerfTest(&brw, (pthread_t*)NULL, thread_num, pthread_create, pthread_join);
+    PerfTest(&brw, (bthread_t*)NULL, thread_num, bthread_start_background, bthread_join);
+
+    //add test 1 rlock for compare
+    PerfTest(&brw, (pthread_t*)NULL, 1, pthread_create, pthread_join);
+    PerfTest(&brw, (bthread_t*)NULL, 1, bthread_start_background, bthread_join);
+
+    //for wlock
+    PerfTest(&brw, (pthread_t*)NULL, thread_num, pthread_create, pthread_join, 1);
+    PerfTest(&brw, (bthread_t*)NULL, thread_num, bthread_start_background, bthread_join, 1);
+
+    //add test 1 wlock for compare
+    PerfTest(&brw, (pthread_t*)NULL, 1, pthread_create, pthread_join, 1);
+    PerfTest(&brw, (bthread_t*)NULL, 1, bthread_start_background, bthread_join, 1);
+}
+
+void* loop_until_stopped(void* arg) {
+    bthread::v2::bthread_rwlock_t *m = (bthread::v2::bthread_rwlock_t*)arg;
+    while (!g_stopped) {
+        int r = rand() % 100;
+        if((r&1)==0)
+        {
+            bthread::v2::rlock_guard rg(*m);
+        }
+        else{
+            bthread::v2::wlock_guard wg(*m);
+        }
+        bthread_usleep(20);
+    }
+    return NULL;
+}
+
+TEST(RwlockTest, mix_thread_types) {
+    g_stopped = false;
+    const int N = 16;
+    const int M = N * 2;
+    // bthread::Mutex m;
+    bthread::v2::bthread_rwlock_t brw;
+    bthread_rwlock_init(&brw, NULL);
+
+    pthread_t pthreads[N];
+    bthread_t bthreads[M];
+    // reserve enough workers for test. This is a must since we have
+    // BTHREAD_ATTR_PTHREAD bthreads which may cause deadlocks (the
+    // bhtread_usleep below can't be scheduled and g_stopped is never
+    // true, thus loop_until_stopped spins forever)
+    bthread_setconcurrency(M);
+    for (int i = 0; i < N; ++i) {
+        ASSERT_EQ(0, pthread_create(&pthreads[i], NULL, loop_until_stopped, &brw));
+    }
+    for (int i = 0; i < M; ++i) {
+        const bthread_attr_t *attr = i % 2 ? NULL : &BTHREAD_ATTR_PTHREAD;
+        ASSERT_EQ(0, bthread_start_urgent(&bthreads[i], attr, loop_until_stopped, &brw));
+    }
+    bthread_usleep(1000L * 1000);
+    g_stopped = true;
+    for (int i = 0; i < M; ++i) {
+        bthread_join(bthreads[i], NULL);
+    }
+    for (int i = 0; i < N; ++i) {
+        pthread_join(pthreads[i], NULL);
+    }
+}
+} // namespace
